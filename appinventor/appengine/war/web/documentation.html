<!DOCTYPE html>
<html lang="en">
   <head>
      <meta charset="utf-8">
      <meta http-equiv="X-UA-Compatible" content="IE=edge">
      <meta name="viewport" content="width=device-width, initial-scale=1">
      <meta name="description" content="">
      <meta name="author" content="">
      <title>VEDILS - Visual environment for designing interactive learning scenarios</title>
      <!-- Bootstrap Core CSS -->
      <link href="vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet" type="text/css">
      <!-- Custom Fonts -->
      <link href="vendor/font-awesome/css/font-awesome.min.css" rel="stylesheet" type="text/css">
      <link href='https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800' rel='stylesheet' type='text/css'>
      <link href='https://fonts.googleapis.com/css?family=Merriweather:400,300,300italic,400italic,700,700italic,900,900italic' rel='stylesheet' type='text/css'>
      <!-- Plugin CSS -->
      <link href="vendor/magnific-popup/magnific-popup.css" rel="stylesheet" type="text/css">
      <!-- Theme CSS -->
      <link href="css/creative.css" rel="stylesheet" type="text/css">
      <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
      <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
      <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
      <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
      <![endif]-->
   </head>
   <body id="page-top">
      <nav id="mainNav" class="navbar navbar-default navbar-fixed-top bg-darkest-gray ">
         <div class="container-fluid">
            <!-- Brand and toggle get grouped for better mobile display -->
            <div class="header-content">
               <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
               <span class="sr-only">Toggle navigation</span> Menu <i class="fa fa-bars"></i>
               </button>
               <a class="navbar-brand page-scroll" href="index.html#portfolio">Back to <strong>VEDILS</strong> Website</a>
            </div>
            <!-- Collect the nav links, forms, and other content for toggling -->
            <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
               <ul class="nav navbar-nav navbar-right">
                  <li>
                     <a class="page-scroll" href="#Releases">RELEASES</a>
                  </li>
                  <li>
                     <a class="page-scroll" href="#Getting">GETTING STARTED</a>
                  </li>
                  <li>
                     <a class="page-scroll" href="#Components">COMPONENTS</a>
                  </li>
                  <li>
                     <a class="page-scroll" href="#Publications">PUBLICATIONS</a>
                  </li>
               </ul>
            </div>
            <!-- /.navbar-collapse -->
         </div>
         <!-- /.container-fluid -->
      </nav>
      <section id="Releases">
         <div class="container">
            <div class="row">
               <div class="col-lg-8 col-lg-offset-2 text-center">
                  <h2 class="section-heading">Releases</h2>
               </div>
               <br>
               <br>
            </div>
            <div class="row">
               <div class="col-lg-10 col-lg-offset-1">
                  <h3>
                     <ul>
                        <li>Version 1.6 [CURRENT]</li>
                        <h4> <ul>
                           <li>Availability of a new component for maintaining conversational experiences via DialogFlow API: <strong>Dialog</strong></li>
                           <li>Several improvements on the component <strong>ActivityTracker</strong> for store data on a Learning Record Store (Learning Locker)</li>
                           <li>Several improvements on the components <strong>SemanticConcept and ConceptExplorer</strong> for query any RDF endpoint</li>
                           <li>Availability of a <strong>xAPI</strong> block category with the xAPI verbs catalog included</li>
                           <li>Availability of a new component for executing any BPMN workflow: <strong>Workflow</strong></li>
                        </ul></h4>
                        <li>Version 1.5</li>
                        <h4><ul>
                           <li>Availability of tree new components for allows viewing objects, images and videos in 360º, the video locally as in streaming:  <strong>VR3DObject</strong>, <strong>VRImage360</strong> and <strong>VRVideo360</strong></li>
                           <li>Availability of a new component for managing bluetooth remote control, allows interacting with a virtual reality environment: <strong>VRController</strong></li>
                           <li>Availability of a new component to set up the options of the virtual reality scene: <strong>VRScene</strong></li>
                           <li>Availability of a <strong>Streams</strong> block category for analysis from the mobile device on live</li>
                           <li>Several improvements on the components <strong>ActivityTracker, ActivitySimpleQuery, and ActivityAggregationQuery</strong> for remote streaming analysis with Apache Flink, for sending notifications to a message queue (Apache Kafka), for a new NoSQL (MongoDB) storage</li>
                           <li>Several improvements on the component <strong>BrainWaveSensor</strong> incorporating new events to collect data from the sensors. </li>
                        </ul></h4>
                        <li>Version 1.4</li>
                        <h4><ul>
                           <li>Availability of a new component for managing devices for brain computer interfaces, such as Emotiv Epoc+ and Emotiv Insight: <strong>BrainwaveSensor</strong></li>
                           <li>Availability of a new component for managing Myo, a wearable gesture control device: <strong>ArmbandGestureSensor</strong></li>
                           <li>Availability of two new components for automatically retrieving information from Wikidata (central storage for Wikipedia): <strong>ConceptExplorer</strong> and <strong>SemanticConcept</strong></li>
                           <li>Availability of a new component for rendering 3D models: <strong>Model3DViewer</strong></li>
                           <li>Several improvements on the component for managing Sphero robots</li>
                        </ul></h4>
                        <li>Version 1.3</li>
                        <h4><ul>
                           <li>Availability of a new component for managing Sphero robots: <strong>SpheroController</strong></li>
                           <li>Availability of new specific components for querying and representing analytical data: <strong>ActivitySimpleQuery</strong>, <strong>ActivityAggregationQuery</strong>, <strong>Chart</strong> and <strong>DataTable</strong></li>
                        </ul></h4>
                        <li>Version 1.2</li>
                        <h4><ul>
                           <li>Availability of a new component for managing gestures: <strong>HandGestureSensor</strong></li>
                           <li>Availability of new components for character recognition in augmented reality scenarios and overlaying an action bar <strong>ARTextTracker</strong> and <strong>ARCameraOverLayer</strong></li>
                           <li>Availability of a new component for messaging: <strong>GoogleCloudMessaging</strong></li>
                           <li>Availability of a new component for communicating with a Internet of the Things service: <strong>ThingSpeakLocationSensor</strong></li>
                           <li>Availability of a new component for retrieving information about the user's device: <strong>DeviceInfo</strong></li>
                           <li>Several improvements on the component for tracking analytical data</li>
                        </ul></h4>
                        <li>Version 1.1</li>
                        <h4><ul>
                           <li>Availability of a component for tracking analytical data: <strong>ActivityTracker</strong></li>
                           <li>Availability of a new component for augmented reality: <strong>ARImageAsset</strong></li>
                           <li>Several improvements on the existing components for augmented reality</li>
                        </ul>
                        <li>Version 1.0</li>
                        <h4><ul>
                           <li>Availability of specific components for augmented reality: <strong>ARCamera</strong>, <strong>ARMarkerTracker</strong>, <strong>ARObjectTracker</strong>, <strong>AR3DModelAsset</strong>, <strong>AR3DImageAsset</strong></li>
                        </ul></h4>
                     </ul>
                  </h3>
               </div>
            </div>
         </div>
      </section>

      <!-- Sección Deploy-->
      <section id="Getting" class=" bg-light-gray">
               <div class="container">
            <div class="row">
               <div class="col-lg-10 col-lg-offset-1 text-center">
                  <h2 class="section-heading">Getting Started</h2>
                  
                  <iframe src='https://canal.uned.es/iframe/5b557960b1111fb6558b4579' id='pumukitiframe' frameborder='0' border='0' width='560' height='315' allowfullscreen></iframe>
                  
                  
                  <hr class="primary">
                  <h3>To work with <strong>VEDILS</strong> you only need a web browser (we recommend Google Chrome) and then access the <a target="_blank" href="http://vedils.uca.es/login">website</a>. VEDILS is composed of two parts: one for the app <strong>design</strong> [Figure 1], where we drag the elements from the toolbox (that can be configured later in the settings tab), and another called <strong>blocks</strong> [Figure 2] where we can define the logic behind the app, by using a visual language.</h3>
                  <br>
                  <h3>
                     Once we have developed our app, we must generate the .apk file in order to install it on our Android mobile devices. To do so [Figure 3] we first need to click on the option “Build - App (save .apk to my computer)”. Once we have copied the .apk file on our mobile device we only need to open the file to install the app. Don’t forget that our device must be configured to install third-party applications. For further information you can watch the <a href="https://youtu.be/OUSKczQluHo" target="_blank">following video</a>.
                  </h3>
               </div>
            </div>
            <br>
            <br>>
            <div class="container-fluid">
               <!-- para que no abra imagen <div class="row no-gutter popup-gallery"> -->
               <div class="row no-gutter">
                  <div class="col-lg-4 col-sm-6">
                     <a href="img/documentation/desing.png" class="portfolio-box">
                        <img src="img/documentation/desing.png" class="img-responsive" alt="">
                        <div class="portfolio-box-caption">
                           <div class="portfolio-box-caption-content">
                              <div class="project-category text-faded">
                                 Figure 1: Desing
                              </div>
                              <div class="project-name">
                                 Expand
                              </div>
                           </div>
                        </div>
                     </a>
                  </div>
                  <div class="col-lg-4 col-sm-6">
                     <a href="img/documentation/blocks.png" class="portfolio-box">
                        <img src="img/documentation/blocks.png" class="img-responsive" alt="">
                        <div class="portfolio-box-caption">
                           <div class="portfolio-box-caption-content">
                              <div class="project-category text-faded">
                                 Figure 2: Blocks
                              </div>
                              <div class="project-name">
                                 Expand
                              </div>
                           </div>
                        </div>
                     </a>
                  </div>
                  <div class="col-lg-4 col-sm-6">
                     <a href="img/documentation/apk.png" class="portfolio-box">
                        <img src="img/documentation/apk.png" class="img-responsive" alt="">
                        <div class="portfolio-box-caption">
                           <div class="portfolio-box-caption-content">
                              <div class="project-category text-faded">
                                 Figure 3: Make an apk for Android
                              </div>
                              <div class="project-name">
                                 Expand
                              </div>
                           </div>
                        </div>
                     </a>
                  </div>
               </div>
               <br>
               <br>
            </div>
         </div>
         <div class="container">
            <div class="row">
               <div class="col-lg-10 col-lg-offset-1 text-center">
                  <hr class="primary">
                  <h3>The appearance of our apps on the design view may not coincide with their display on the mobile devices. To get an idea in real time of what our app looks like, how virtual objects are displayed, etc. you can use the <a href="https://play.google.com/store/apps/details?id=es.uca.vedils"><strong>VEDILS Companion</strong></a> app.
                     <br>
                     <br>
                     <br>
                  </h3>
               </div>
               <div class="row">
                  <div class="col-lg-10 col-lg-offset-1">
                     <h3>
                        <strong>Steps to tests our VEDILS apps</strong>
                        <ul>
                           <li>
                                First we must install <a href="https://play.google.com/store/apps/details?id=es.uca.vedils"><strong>VEDILS Companion</strong></a> on our mobile device. Then we must connect (through WiFi) the mobile device with the app we are developing.
                           </li>
                           <li>Tap “Connect - Al Companion” on the <strong>VEDILS</strong> website. A new window will appear with a QR code.
                           </li>
                           <li>
                              Open the <a href="https://play.google.com/store/apps/details?id=es.uca.vedils"><strong>VEDILS Companion</strong></a> app on our mobile device. Then tap “Scan QR Code” option and point to the QR code provided by <strong>VEDILS</strong>.
                           </li>
                        </ul>
                     </h3>
                  </div>
               </div>
            </div>
            <div class="row no-gutter popup-gallery">
               <div class="col-lg-6 col-sm-6 col-lg-offset-3">
                  <a href="img/documentation/qrcode.png" class="portfolio-box">
                     <img src="img/documentation/qrcode.png" class="img-responsive" alt="">
                     <div class="portfolio-box-caption">
                        <div class="portfolio-box-caption-content">
                           <div class="project-category text-faded">
                           </div>
                           <div class="project-name">
                              Expand
                           </div>
                        </div>
                     </div>
                  </a>
               </div>
            </div>
         </div>
      </section>
      <section id="Components">
         <div class="container">
            <div class="row">
               <div class="col-lg-10 col-lg-offset-1 text-center">
                  <h2 class="section-heading">VEDILS COMPONENTS (extensions to MIT App Inventor)</h2>
                  <hr class="primary">
               </div>
            </div>
            <div class="row">
               <div class="col-lg-10 col-lg-offset-1">
                  <h3>
                     <strong>VEDILS Augmented reality <a href="vedilsAR.html">(+Info)</a></strong>
                     <ul>
                        <li>AR3DModelAsset: It allows showing 3D models in .OBJ, .3DS and .MDS format.</li>
                        <li>ARImageAsset: It shows images in 2D format.</li>
                        <li>ARCamera: It opens the camera and displays the augmented reality.</li>
                        <li>ARCameraOverLayer: It shows information and buttons on the image in real-time and captured by the camera.</li>
                        <li>ARTextTracker: Text recognition.</li>
                        <li>ARMarkerTracker: Recognition of up to 512 augmented reality markers. A PDF file with custom markers is available <a href="rsc/markersVEDILS.pdf">here</a>.</li>
                        <li>ARObjectTracker: Image recognition.</li>
                     </ul>
                  </h3>
               </div>
            </div>
            
            <div class="row">
               <div class="col-lg-10 col-lg-offset-1">
                  <h3>
                     <strong>VEDILS Virtual reality <a href="vedilsVR.html">(+Info)</a></strong>
                     <ul>
                        <li>VR3DObject: It allows view 3D objects in .OBJ, .3DS, .MD2 format.</li>
                        <li>VRController:It set up a bluetooth control remote, allowing interact with a virtual reality environment.</li>
                        <li>VRImage360: It lets view 360 degree images.</li>
                        <li>VRScene: It set up the options of the virtual reality scene.</li>
                        <li>VRVideo360: It shows videos in 360º in local as in streaming.</li>
                     </ul>
                  </h3>
               </div>
            </div>
            <div class="row">
               <div class="col-lg-10 col-lg-offset-1">
                  <h3>
                     <strong>VEDILS Learning Analytics <a href="learningAnalytics.html">(+Info)</a></strong>
                     <ul>
                        <li>Block category "Streams" incorporating functions to work with streams: filter, map, reduce, sort and limit.</li>
                        <li>ActivityAggregationQuery: It allows to issue aggregation queries to the Fusion Tables and MongoDB service in order to retrieve metrics, it allows too send stream queries to Apache Flink.</li>
                        <li>ActivitySimpleQuery: It allows to issue queries to the Fusion Tables service in order to select data (FusionTables, MongoDB and streaming queries with Apache Flink).</li>
                        <li>ActivityTracker: It allows to register, on Google Fusion Tables and MongoDB, the user’s interaction with the app, it allows to send the data to a message queue (Apache Kafka).</li>
                        <li>Chart: It displays a (bar/line) chart with data.</li>
                        <li>DataTable: It displays a table with data.</li>
                     </ul>
                  </h3>
               </div>
            </div>
            <div class="row">
               <div class="col-lg-10 col-lg-offset-1">
                  <h3>
                     <strong>VEDILS Interactions</strong>
                     <ul>
                        <li>BrainwaveSensor: It allows to capture brain activity patterns  if a <a href="https://www.emotiv.com/" target="_blank">Emotiv</a> device is connected (see <strong><a href="http://ior.ad/tUh">tutorial</a></strong>).</li>
                        <li>ArmbandGestureSensor: It allows to capture user arm gestures if a <a href="https://www.myo.com/" target="_blank">Myo</a> device is connected (see <strong><a href="http://ior.ad/tUo">tutorial</a></strong>).</li>
                        <li>HandGestureSensor: It allows to capture user hand gestures if a <a href="https://www.leapmotion.com/" target="_blank">Leap Motion</a> device is connected (see <strong><a href="http://ior.ad/tNZ">tutorial</a></strong>). To be able to use this device you must install the <a href="rsc/LeapDaemon-release-2.3.2+35031.apk">SDKLeapMotion</a>.</li>
                        <li>Dialog: It allows to recognize voice commands and trigger proper actions according to a specific dialog defined with <a href="https://dialogflow.com/" target="_blank">DialogFlow</a>.</li>
                     </ul>
                  </h3>
               </div>
            </div>
                   
            <div class="row">
               <div class="col-lg-10 col-lg-offset-1">
                  <h3>
                     <strong>VEDILS Robotics <a href="..\web\img\documentation\vedilsRobotics\SpheroControllerDoc.pdf">(+Info)</a></strong>
                     <ul>
                        <li>SphereController: It allows to remotely control Sphero devices and receive events such as collisions</li>
                     </ul>
                  </h3>
               </div>
            </div>
            <div class="row">
               <div class="col-lg-10 col-lg-offset-1">
                  <h3>
                     <strong>VEDILS Knowledge</strong>
                     <ul>
                        <li>ConceptExplorer: It automatically obtains data entities from Wikipedia articles (see <strong><a href="http://ior.ad/tUW">tutorial</a></strong>).</li>
                        <li>SemanticConcept: It allows to retrieve data about specific concepts, from general properties (id, description, image, etc.) to domain specific properties</li>
                     </ul>
                  </h3>
               </div>
            </div>
            <div class="row">
               <div class="col-lg-10 col-lg-offset-1">
                  <h3>
                     <strong>VEDILS Comunications</strong>
                     <ul>
                        <li>DeviceInfo: It obtains information from the device in order to identify it.</li>
                        <li>GoogleCloudMessaging: It allows to send messages among different mobile devices.</li>
                        <li>ThingSpeakLocationSensor: Tests with ThingSpeak in order to retrieve and show the device’s location.</li>
                     </ul>
                  </h3>
               </div>
            </div>
            
            <div class="row">
               <div class="col-lg-10 col-lg-offset-1">
                  <h3>
                     <strong>Experimental</strong>
                     <ul>
                        <li>Model3DViewer: It allows rendering 3D models in the app (see <a href="http://ior.ad/tNz"><strong>tutorial</strong></a>).</li>
                     </ul>
                  </h3>
               </div>
            </div>
            <div class="row">
               <div class="col-lg-10 col-lg-offset-1">
                  <h3>
                     <strong>Improved Components</strong>
                     <ul>
                        <li>SpeechRecognizer: is a new component, that changes the language of speech recognition and dictation, example uses: de, en, es, fr, it.
                        </li>
                     </ul>
                  </h3>
               </div>
            </div>
         </div>
      </section>
      <section id="Publications" class=" bg-light-gray">
         <div class="container">
            <div class="row">
               <div class="col-lg-8 col-lg-offset-2 text-center">
                  <h2 class="section-heading">PUBLICATIONS</h2>
               </div>
               <br>
               <br>
            </div>
            <div class="row">
               <div class="col-lg-10 col-lg-offset-1">
                  <h3>
                  [Papers in proceedings]
                  </h3>
                  <h4>
                  <ul>
                     <li>Mota, J. M., Ruiz-Rube, I., Dodero, J. M., & Arnedillo-Sánchez, I. (2018). Augmented reality mobile app development for all. Computers & Electrical Engineering, 65, 250-260.</li>
                     <li>Rodríguez-Corral J.M., Ruiz-Rube, I., Civit-Balcells, A., Mota J.M., Morgado-Estévez A.,  Dodero, J.M. A Study on the Suitability of Visual Languages for Robot Programming. (To be published).</li>
                  </ul>
                  </h4>
                  <h3>
                  [Book chapters]
                  </h3>
                  <h4>
                  <ul>
                     <li> Mota, J. M., Ruiz-Rube, I., Dodero, J. M., Person, T., & Arnedillo-Sánchez, I. (2018). Learning Analytics in Mobile Applications Based on Multimodal Interaction. In Software Data Engineering for Network eLearning Environments (pp. 67-92). Springer, Cham.</li>
                  </ul>
                  </h4>
                  <h3>
                  [Papers in conference proceedings]
                  </h3>
                  <h4>
                  <ul>
                     <li>Berns, A., Mota, J.M., Ruiz-Rube, Iván and Dodero, J.M., (2018, October). Exploring the potential of a 360º video application for foreign language learning. In Proceedings of the 6th International Conference on Technological Ecosystems for Enhancing Multiculturality. ACM</li>
                     <li>Person, T., Mota, J.M., Listán, M.C., Ruiz-Rube, I., Dodero, J.M., Rambla, F.,  Muriel, C., Ruiz, A., and Vidal J.M. (2018, October). Authoring of educational mobile apps for the mathematics-learning analysis. In Proceedings of the 6th International Conference on Technological Ecosystems for Enhancing Multiculturality. ACM</li>
                     <li>Person, T., Ruiz-Rube, I., and Dodero, J.M. (2018, May)  Exploiting the Web of Data for the creation of mobile apps by non-expert programmers. In Proceedings of the International Workshop on Learning and Education with Web Data. ACM Conference on Web Science. </li>
                     <li>Dodero, J. M., Mota, J. M., & Ruiz-Rube, I. (2017, October). Bringing computational thinking to teachers' training: a workshop review. In Proceedings of the 5th International Conference on Technological Ecosystems for Enhancing Multiculturality (p. 4). ACM.</li>
                     <li>Balderas, A., Ruiz-Rube, I., Mota, J. M., Dodero, J. M., & Palomo-Duarte, M. (2016, November). A development environment to customize assessment through students interaction with multimodal applications. In Proceedings of the Fourth International Conference on Technological Ecosystems for Enhancing Multiculturality (pp. 1043-1048). ACM.</li>
                     <li>Mota, J. M., Ruiz-Rube, I., Dodero, J. M., & Figueiredo, M. (2016). Visual Environment for Designing Interactive Learning Scenarios with Augmented Reality. In Proceedings of the 12th International Conference on Mobile Learning 2016</li>
                     <li>Ruiz-Rube, I., Mota, J. M., Person, T., Berns, A., & Dodero, J. M. (2016, September). Autoría y analítica de aplicaciones móviles educativas multimodales. In Proceedings of SIIE 2016. Simposio Internacional de Informática Educativa</li>
             		 <li>Ruiz-Rube, I., Mota, J. M., Dodero, J.M. (2016). Diseño de escenarios de aprendizaje interactivos para su despliegue sobre dispositivos móviles. In Libro de actas de XIII Foro Internacional sobre Evaluación de la Calidad de la Investigación y de la Educación Superior</li>
             
                  </ul>
                  </h4>
                  <h3>
                     [Posters and other communications]
                  </h3>
                     <h4>
                     <ul>
                        <li>Person, T., Ruiz-Rube, I., & Dodero, J. M. (2018). Towards a Methodology and a Toolkit to Analyse Data for Novices in Computer Programming. Learning Analytics Summer Institute Spain
                        <li>Mota, J.M., and Ruiz-Rube, I.. (2017). VEDILS: a toolkit for developing Android mobile apps supporting mobile analytics. Seventh European Business Intelligence & Big Data Summer School (eBISS 2017)
                        <li>Ruiz-Rube, I., and Mota, J.M. (2017). A BI platform for analysing mobile app development process based on visual languages. Seventh European Business Intelligence & Big Data Summer School (eBISS 2017)
                        <li>Person, T. Ruiz-Rube, I. , Sibón, T. (2017). Aportación de la Ingeniería Informática en la creación del APP “A manos llenas”. Cuentos accesibles como recurso didáctico. Congreso Internacional Sobre Escritura Y Sordera
                        <li>Mota, J.M, Ruiz-Rube, I., Dodero, J.M. (2017). Desarrollo sencillo de apps para la enseñanza y aprendizaje de la lengua de signos. Congreso Internacional Sobre Escritura Y Sordera
                     </ul>
                     </h4>
                  
               </div>
            </div>
         </div>
      </section>
      <!--
         <section id="05" class=" bg-light-gray">
             <div class="container">
                 <div class="row">
                     <div class="col-lg-8 col-lg-offset-2 text-center">
                         <h2 class="section-heading">Resources</h2>
                         <hr class="primary">
         
                     </div>
                     <br>
                     <br>
                 </div>
                 <div class="row">
                     <div class="col-lg-10 col-lg-offset-1">
                         <h3>
                         <strong>External Resources</strong>
                         <ul>
                     
                     <li><a href="http://appinventor.mit.edu/appinventor-sources/">App Inventor sources</a></li>
                     <li><a href="https://developer.vuforia.com/">Vuforia developers</a></li>
                     <li><a href="https://developer.leapmotion.com/">Leap Motion developers</a></li>
                     <li><a href="https://support.google.com/fusiontables/answer/2571232">Google Fusion Tables</a></li>
                     <li><a href="https://www.babel3d.com/">Babel 3D for converting 3D models</a></li>
                     <li><a href="https://a360.autodesk.com/viewer">A360 Viewer for visualizing models on browser</a></li>
                 </ul>
                     </h3>
                     </div>
                 </div>
             </div>
         </section>
         
         -->
      <!-- Google Analytics-->
      <script>
         (function (i, s, o, g, r, a, m) {
             i['GoogleAnalyticsObject'] = r;
             i[r] = i[r] || function () {
                 (i[r].q = i[r].q || []).push(arguments)
             }, i[r].l = 1 * new Date();
             a = s.createElement(o),
                 m = s.getElementsByTagName(o)[0];
             a.async = 1;
             a.src = g;
             m.parentNode.insertBefore(a, m)
         })(window, document, 'script', 'https://www.google-analytics.com/analytics.js', 'ga');
         
         ga('create', 'UA-72236489-1', 'auto');
         ga('send', 'pageview');
      </script>
      <!-- jQuery -->
      <script src="vendor/jquery/jquery.min.js"></script>
      <!-- Bootstrap Core JavaScript -->
      <script src="vendor/bootstrap/js/bootstrap.min.js"></script>
      <!-- Plugin JavaScript -->
      <script src="http://cdnjs.cloudflare.com/ajax/libs/jquery-easing/1.3/jquery.easing.min.js"></script>
      <script src="vendor/scrollreveal/scrollreveal.min.js"></script>
      <script src="vendor/magnific-popup/jquery.magnific-popup.min.js"></script>
      <!-- Theme JavaScript -->
      <script src="js/creative.min.js"></script>
   </body>
</html>